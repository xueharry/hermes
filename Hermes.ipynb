{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hermes\n",
    "Sequence to sequence chatbot trained on Facebook messenger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, Dropout, recurrent\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Configuration(object):\n",
    "    \"\"\"Class for holding configuration settings\"\"\"\n",
    "    \n",
    "CONFIG = Configuration()\n",
    "CONFIG.max_input_len = 10 # Maximum number of timesteps in an input sequence\n",
    "CONFIG.max_output_len = 10 # Maximum number of timesteps in an output sequence (9 for words, 1 for <EOS>)\n",
    "UNKNOWN_TOKEN = \"<UNKNOWN>\"\n",
    "EOS = \"<EOS>\"\n",
    "\n",
    "# Training parameters\n",
    "CONFIG.batch_size = 16\n",
    "CONFIG.epochs = 500\n",
    "\n",
    "CONFIG.amount_of_dropout = 0.1\n",
    "CONFIG.hidden_size = 50 # 500\n",
    "CONFIG.initialization = \"he_normal\" # Gaussian initialization scaled by fan-in (He et al., 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Facebook Messenger messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read html\n",
    "page = urllib.urlopen('data/messages.htm').read()\n",
    "soup = BeautifulSoup(page, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contents_div = soup.body.div.next_sibling\n",
    "# Get div of room groupchat\n",
    "groupchat_div = contents_div.div.div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of all messages in this groupchat\n",
    "groupchat_messages = []\n",
    "\n",
    "groupchat_p = groupchat_div.find_all(\"p\")\n",
    "for p in groupchat_p:\n",
    "    groupchat_messages.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of messages: 9257\n",
      "[u'leggo', u'hebrew bible leffo', u'looks like culture and belief is all that is left', u'Ez', u'workload is only ~9.4 hours per week we can do this guys', u'graduate level probability', u\"stat 210 let's go\", u'yah', u'different instructor though', u'according to my.harvard']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Clean\n",
    "print \"Number of messages:\", len(groupchat_messages)\n",
    "print groupchat_messages[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8255\n"
     ]
    }
   ],
   "source": [
    "# Filter for messages < maximum input length\n",
    "filtered = []\n",
    "for message in groupchat_messages:\n",
    "    if len(message.split(\" \")) < CONFIG.max_output_len:\n",
    "        filtered.append(message)\n",
    "\n",
    "groupchat_messages = filtered\n",
    "print(len(groupchat_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create pickle dump of all messages\n",
    "pickle.dump(groupchat_messages, open('data/groupchat.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of unique tokens used\n",
    "tokens = []\n",
    "for message in groupchat_messages:\n",
    "    tokens += message.split(' ')\n",
    "tokens = list(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create question, answer pairs using alternating pairs of messages\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for i in range(len(groupchat_messages) - 1):\n",
    "    questions.append(groupchat_messages[i].split(\" \"))\n",
    "    answers.append(groupchat_messages[i + 1].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Language(object):\n",
    "    def __init__(self, tokens, maxlen):\n",
    "        # Add STOP and UNKNOWN_TOKEN to vocabulary\n",
    "        tokens.append(UNKNOWN_TOKEN)\n",
    "        self.tokens = sorted(set(tokens))\n",
    "        # Reserve index 0 for the EOS token\n",
    "        self.tokens_indices = dict((t, i + 1) for i, t in enumerate(self.tokens))\n",
    "        self.indices_tokens = dict((i + 1, t) for i, t in enumerate(self.tokens))\n",
    "        self.tokens.insert(0, EOS)\n",
    "        self.tokens_indices[EOS] = 0\n",
    "        self.indices_tokens[0] = EOS\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        \"\"\"The number of unique tokens\"\"\"\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def encode(self, l):\n",
    "        \"\"\"Encode a list of tokens as one-hot\"\"\"\n",
    "        X = np.zeros((self.maxlen, self.size), dtype=np.bool)\n",
    "        for i, item in enumerate(l):\n",
    "            try:\n",
    "                X[i, self.tokens_indices[item]] = 1\n",
    "            except KeyError:\n",
    "                X[i, self.tokens_indices[UNKNOWN_TOKEN]] = 1\n",
    "        # Insert EOS token\n",
    "        X[i + 1, self.tokens_indices[EOS]] = 1\n",
    "        return X\n",
    "\n",
    "    def decode(self, X):\n",
    "        \"\"\"Decode array of predicted token indices into a array of predicted tokens\"\"\"\n",
    "        result = []\n",
    "        for x in X:\n",
    "            if self.indices_tokens[x] == EOS:\n",
    "                return result\n",
    "            result.append(self.indices_tokens[x])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def most_likely_seq_probs(self, X):\n",
    "        \"\"\"Return vector of probabilities for the most likely sequence\"\"\"\n",
    "        probs = np.array([])\n",
    "\n",
    "        for x in X:\n",
    "            most_likely_ind = x.argmax()\n",
    "            most_likely_prob = x.max()\n",
    "\n",
    "            # Check for end-of-line token and return if found\n",
    "            if most_likely_ind == self.tokens_indices[EOS]:\n",
    "                return probs\n",
    "            else:\n",
    "                probs = np.append(probs, most_likely_prob)\n",
    "\n",
    "        return probs\n",
    "\n",
    "def generate_sample_weights(Y):\n",
    "    sample_weights = np.zeros((len(Y), CONFIG.max_output_len))\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        for j in range(CONFIG.max_output_len):\n",
    "            if np.any(Y[i, j]):\n",
    "                sample_weights[i,j] = 1\n",
    "\n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot encode all inputs and outputs\n",
    "language = Language(tokens, CONFIG.max_output_len)\n",
    "X = np.array([language.encode(question) for question in questions])\n",
    "Y = np.array([language.encode(question) for answer in answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train-validation split\n",
    "X_train, X_val, Y_train, Y_val, questions_train, questions_val, answers_train, answers_val = train_test_split(X, Y, questions, answers, test_size=0.1)\n",
    "# Generate sample weights\n",
    "# sample_weights = generate_sample_weights(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_model(output_dim):\n",
    "    \"\"\"Generate the model\"\"\"\n",
    "    print('Building model...')\n",
    "    model = Sequential()\n",
    "    # Encoding layers\n",
    "    model.add(recurrent.LSTM(CONFIG.hidden_size, input_shape=(None, output_dim), kernel_initializer=CONFIG.initialization, return_sequences=True))\n",
    "    model.add(Dropout(CONFIG.amount_of_dropout))\n",
    "    model.add(recurrent.LSTM(CONFIG.hidden_size, input_shape=(None, output_dim), kernel_initializer=CONFIG.initialization, return_sequences=False))\n",
    "    model.add(Dropout(CONFIG.amount_of_dropout))\n",
    "    # Repeat hidden representation\n",
    "    model.add(RepeatVector(CONFIG.max_output_len))\n",
    "    # Decoding layers\n",
    "    model.add(recurrent.LSTM(CONFIG.hidden_size, return_sequences=True, kernel_initializer=CONFIG.initialization))\n",
    "    model.add(Dropout(CONFIG.amount_of_dropout))\n",
    "    model.add(recurrent.LSTM(CONFIG.hidden_size, return_sequences=True, kernel_initializer=CONFIG.initialization))\n",
    "    model.add(Dropout(CONFIG.amount_of_dropout))\n",
    "\n",
    "    # For each of step of the output sequence, decide which token should be chosen\n",
    "    model.add(TimeDistributed(Dense(output_dim, kernel_initializer=CONFIG.initialization)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])#, sample_weight_mode=\"temporal\")\n",
    "    print('Model successfully built')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# def print_predictions(model, output_language, X, X_text, Y_text):\n",
    "#     \"\"\"Print out errors on selected examples\"\"\"\n",
    "#     print()\n",
    "#     for rowX, rowX_text, rowY_text in zip(X, X_text, Y_text):\n",
    "#         preds = model.predict_classes(rowX[np.newaxis], verbose=0)\n",
    "#         preds_probs = model.predict(rowX[np.newaxis], verbose=0)\n",
    "#         q = ' '.join(rowX_text)\n",
    "#         correct = ' '.join(rowY_text)\n",
    "#         guess = ' '.join(output_language.decode(preds[0]))\n",
    "#         confidences = output_language.most_likely_seq_probs(preds_probs[0])\n",
    "\n",
    "#         print('Question:', q)\n",
    "#         print('Answer:', correct)\n",
    "#         print('Guess:', guess)\n",
    "#         print('Confidences', confidences)\n",
    "#         print('---')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnEpochEndCallback(Callback):\n",
    "    \"\"\"Execute this every end of epoch\"\"\"\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        mask = sample(range(len(X_val)), 50)\n",
    "        X_sample, X_text_sample, Y_text_sample = X_val[mask], np.array(questions_val)[mask], np.array(answers_val)[mask] \n",
    "        language = Language(tokens, CONFIG.max_output_len)\n",
    "        print_predictions(self.model, language, X_sample, X_text_sample, Y_text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Model successfully built\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, None, 50)          1304000   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 10, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 10, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 10, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 10, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 10, 50)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 10, 6469)          329919    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 6469)          0         \n",
      "=================================================================\n",
      "Total params: 1,694,519\n",
      "Trainable params: 1,694,519\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "8254/8254 [==============================] - 35s - loss: 5.2435 - acc: 0.1353    \n",
      "Epoch 2/500\n",
      "8254/8254 [==============================] - 35s - loss: 2.0937 - acc: 0.3798    \n",
      "Epoch 3/500\n",
      "8254/8254 [==============================] - 35s - loss: 1.5363 - acc: 0.5052    \n",
      "Epoch 4/500\n",
      "8254/8254 [==============================] - 35s - loss: 1.2700 - acc: 0.5922    \n",
      "Epoch 5/500\n",
      "1264/8254 [===>..........................] - ETA: 29s - loss: 1.1622 - acc: 0.6313"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d53e7c5b0c79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mON_EPOCH_END_CALLBACK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOnEpochEndCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSTOP_CALLBACK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = generate_model(language.size)\n",
    "ON_EPOCH_END_CALLBACK = OnEpochEndCallback()\n",
    "STOP_CALLBACK = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=5)\n",
    "history = model.fit(x=X, y=Y, batch_size=CONFIG.batch_size, epochs=CONFIG.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "are you guys going to lecture section section\n",
      "what are you doing\n",
      "are you guys going to lecture section section\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = raw_input()\n",
    "    \n",
    "    # Tokenize input and embed\n",
    "    x = np.expand_dims(language.encode(question.split(\" \")), axis=0)\n",
    "    # Predict\n",
    "    preds = model.predict_classes(x, verbose=0)\n",
    "    guess = ' '.join(language.decode(preds[0]))\n",
    "    print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
